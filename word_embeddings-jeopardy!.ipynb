{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep NLP - Word Embeddings\n",
    "\n",
    "Think back to NLP as we've understood it so far.\n",
    "\n",
    "If we've had some luck with NLP modeling, likely with a NaiveBayes algorithm, we were able to illustrate some correlations between words and some other feature of interest.\n",
    "\n",
    "But to whatever extent that our models were able to make connections and pick up on correlations, they did this *without any understanding of the **meaning** of the words in question*.\n",
    "\n",
    "Let's think for a minute about words and objective meanings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make sense of meaning for computational purposes by thinking about meaning in terms of similarity, i.e. thinking about meaning *holistically*.\n",
    "\n",
    "Q. Is there any precedent for this way of thinking about meaning? <br/>\n",
    "A. [Yes](https://plato.stanford.edu/entries/meaning-holism/#ArgForMeaHol)\n",
    "\n",
    "So what will this look like for us?\n",
    "\n",
    "*Remember cosine similarity?*\n",
    "\n",
    "$\\rightarrow$We'll have much the same idea here: Associate each word with values along particular dimensions in a multi-dimensional space. If we had a dimension for *softness*, for example, then pillows and marshmallows would score higher on it than rocks and bricks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is Gensim? See [here](https://en.wikipedia.org/wiki/Gensim) and [here](https://radimrehurek.com/gensim/). But, basically, gensim is a package with lots of topic-modeling and NLP tools, inlcuding Word2Vec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the data [here!](https://drive.google.com/file/d/0BwT5wj_P7BKXb2hfM3d2RHU1ckE/view) (Just click 'Download')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the data\n",
    "\n",
    "import json\n",
    "\n",
    "with open('JEOPARDY_QUESTIONS1.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216930"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': 'HISTORY',\n",
       " 'air_date': '2004-12-31',\n",
       " 'question': \"'For the last 8 years of his life, Galileo was under house arrest for espousing this man's theory'\",\n",
       " 'value': '$200',\n",
       " 'answer': 'Copernicus',\n",
       " 'round': 'Jeopardy!',\n",
       " 'show_number': '4680'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the first element in our list\n",
    "\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many words do we have?\n",
    "\n",
    "len(data[0]['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'For\",\n",
       " 'the',\n",
       " 'last',\n",
       " '8',\n",
       " 'years',\n",
       " 'of',\n",
       " 'his',\n",
       " 'life,',\n",
       " 'Galileo',\n",
       " 'was',\n",
       " 'under',\n",
       " 'house',\n",
       " 'arrest',\n",
       " 'for',\n",
       " 'espousing',\n",
       " 'this',\n",
       " \"man's\",\n",
       " \"theory'\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try that again!\n",
    "\n",
    "data[0]['question'].split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[0]['question'].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3169994"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = 0\n",
    "for clue in data:\n",
    "    length += len(clue['question'].split(' '))\n",
    "length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec requires that our text have the form of a list\n",
    "# of 'sentences', where each sentence is itself a list of\n",
    "# words. How can we put our _Jeopardy!_ clues in that shape?\n",
    "\n",
    "import string\n",
    "text = []\n",
    "\n",
    "for clue in data:\n",
    "    sentence = clue['question'].translate(str.maketrans('', '',\n",
    "                                                        string.punctuation)).split(' ')\n",
    "    \n",
    "    new_sent = [word.lower() for word in sentence]\n",
    "    set_sent = set(new_sent)\n",
    "    \n",
    "    text.append(list(set_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['last',\n",
       " 'for',\n",
       " 'of',\n",
       " 'theory',\n",
       " 'this',\n",
       " 'was',\n",
       " 'his',\n",
       " 'years',\n",
       " 'galileo',\n",
       " 'under',\n",
       " '8',\n",
       " 'the',\n",
       " 'house',\n",
       " 'arrest',\n",
       " 'espousing',\n",
       " 'mans',\n",
       " 'life']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the new structure of our first clue\n",
    "\n",
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the model is simply a matter of\n",
    "# instantiating a Word2Vec object.\n",
    "\n",
    "model = gensim.models.Word2Vec(text, sg=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuous Bag of Words vs. Skipgram\n",
    "\n",
    "<a href=\"https://www.researchgate.net/figure/Illustration-of-the-Skip-gram-and-Continuous-Bag-of-Word-CBOW-models_fig1_281812760\"><img src=\"https://www.researchgate.net/profile/Wang_Ling/publication/281812760/figure/fig1/AS:613966665486361@1523392468791/Illustration-of-the-Skip-gram-and-Continuous-Bag-of-Word-CBOW-models.png\" alt=\"Illustration of the Skip-gram and Continuous Bag-of-Word (CBOW) models.\"/></a>\n",
    "\n",
    "[More on Skipgram](https://towardsdatascience.com/word2vec-skip-gram-model-part-1-intuition-78614e4d6e0b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11006798, 14853590)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To train, call 'train()'!\n",
    "\n",
    "model.train(text, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2970718"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking word count\n",
    "\n",
    "model.corpus_total_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x1a2be2c048>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The '.wv' attribute stores the word vectors\n",
    "\n",
    "model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.18835004, -0.10051052,  0.56742996, -0.38782132,  0.05395151,\n",
       "        0.30893523,  0.01885724,  0.00512805,  0.34733975, -0.42252317,\n",
       "       -0.02703452, -0.37947437, -0.02648863, -0.22058631, -0.12377359,\n",
       "        0.3034612 ,  0.19703291,  0.43381453, -0.01943327,  0.1378722 ,\n",
       "       -0.12958533,  0.19817032,  0.40009233, -0.18560956, -0.03262196,\n",
       "       -0.03280225,  0.7176073 , -0.68748313,  0.2696547 ,  0.236288  ,\n",
       "        0.05716058, -0.15227845,  0.02512128,  0.09427069,  0.12817399,\n",
       "       -0.14056052,  0.28812647, -0.07106934, -0.07075839,  0.32485816,\n",
       "       -0.26228067,  0.57501024,  0.20029369,  0.3513924 ,  0.33409947,\n",
       "        0.33749396,  0.18212356, -0.19127296,  0.97023445, -0.19185641,\n",
       "       -0.01827691, -0.13421504,  0.33293837, -0.09672356,  0.61728305,\n",
       "       -0.1630977 ,  0.24887839,  0.19782183, -0.09601402, -0.47092262,\n",
       "       -0.14621574, -0.04865019,  0.06088542, -0.12594233,  0.30159527,\n",
       "       -0.24800242,  0.28298506, -0.08135349, -0.152371  , -0.16002478,\n",
       "        0.27598995, -0.05652137, -0.62239975,  0.42286026,  0.23654282,\n",
       "        0.16530596,  0.46345592, -0.0581538 , -0.08800023, -0.21966194,\n",
       "       -0.4013282 , -0.02150734, -0.4132767 ,  0.14915437, -0.45299995,\n",
       "       -0.2713029 , -0.01059563,  0.37590492, -0.05974306,  0.6322019 ,\n",
       "       -0.37676528, -0.25229338, -0.26397148,  0.23457496, -0.01792731,\n",
       "        0.0642881 , -0.11386175, -0.23971866,  0.6341738 , -0.15338555],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The vectors are keyed by the words\n",
    "\n",
    "model.wv['child']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['child'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size is 100 because the default is 100. Usually reasonable, but should go up as the number of words goes up. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.wv methods\n",
    "#### 'most_similar()' and 'similarity()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('linen', 0.7968616485595703),\n",
       " ('ornaments', 0.7818689346313477),\n",
       " ('dutchborn', 0.7670450210571289),\n",
       " ('nativity', 0.7597681283950806),\n",
       " ('decorative', 0.7596691846847534),\n",
       " ('millet', 0.758497953414917),\n",
       " ('crafted', 0.7544798851013184),\n",
       " ('supplement', 0.7515498399734497),\n",
       " ('unglazed', 0.7466052770614624),\n",
       " ('integral', 0.7461913824081421)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('furniture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5330559"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('furniture', 'jewelry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('carnivore', 0.8060418367385864),\n",
       " ('endangered', 0.800355851650238),\n",
       " ('preys', 0.786952555179596),\n",
       " ('feline', 0.7785636186599731),\n",
       " ('marsupial', 0.7752657532691956),\n",
       " ('ivorybilled', 0.7725008130073547),\n",
       " ('scavenger', 0.7683324813842773),\n",
       " ('vulpes', 0.7597392201423645),\n",
       " ('beetle', 0.7591995000839233),\n",
       " ('horned', 0.7591184377670288)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['cat', 'animal', 'pet', 'mammal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following 'equations':\n",
    "\n",
    "King + Woman - Man = x\n",
    "\n",
    "Brother + Woman - Man = y\n",
    "\n",
    "What values would you suggest for x and y here?\n",
    "\n",
    "Clearly, getting good answers to these equations depends on understanding the *meanings* of the underlying words.\n",
    "\n",
    "Or does it? The `most_similar()` method takes a 'negative' parameter as well as a 'positive' one, so we can consult our trained word vectors to see how they would answer these questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('domesticated', 0.3434196710586548),\n",
       " ('breed', 0.3179727792739868),\n",
       " ('bird', 0.2775746285915375),\n",
       " ('grow', 0.2703922390937805),\n",
       " ('ago', 0.2653577923774719),\n",
       " ('species', 0.26091259717941284),\n",
       " ('arachnid', 0.2581769526004791),\n",
       " ('creatures', 0.2569670081138611),\n",
       " ('dog', 0.25542062520980835),\n",
       " ('extinct', 0.2506164312362671)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['cat', 'animal'], negative='pet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('throne', 0.28611981868743896),\n",
       " ('bride', 0.2642226815223694),\n",
       " ('empress', 0.26002126932144165),\n",
       " ('heir', 0.23214277625083923),\n",
       " ('heroine', 0.22555987536907196),\n",
       " ('princess', 0.2192891389131546),\n",
       " ('reigned', 0.2105431854724884),\n",
       " ('herself', 0.20507055521011353),\n",
       " ('husband', 0.18874485790729523),\n",
       " ('constantine', 0.18830817937850952)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['king', 'woman'], negative='man')#, topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fargo', 0.6736178398132324),\n",
       " ('coanchor', 0.6470738649368286),\n",
       " ('registry', 0.6416285037994385),\n",
       " ('viacom', 0.6360081434249878),\n",
       " ('tyson', 0.635170042514801),\n",
       " ('bruin', 0.6328413486480713),\n",
       " ('cnbc', 0.6272039413452148),\n",
       " ('sweetheart', 0.625778317451477),\n",
       " ('drivein', 0.6234688758850098),\n",
       " ('jacksonville', 0.6191979050636292)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive='usa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('eh', 0.677048921585083),\n",
       " ('palestinian', 0.6678165197372437),\n",
       " ('indonesia', 0.6666308641433716),\n",
       " ('northwestern', 0.664191722869873),\n",
       " ('venezuela', 0.6622143983840942),\n",
       " ('nez', 0.6605390310287476),\n",
       " ('zimbabwe', 0.6599727272987366),\n",
       " ('indianas', 0.6599428653717041),\n",
       " ('timor', 0.6578361988067627),\n",
       " ('ceuta', 0.6559556722640991)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('canada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar('shakespeare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar('greg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar('jefferson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar('washington')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('exile', 0.2267046421766281),\n",
       " ('emperors', 0.22108100354671478),\n",
       " ('emperor', 0.220118448138237),\n",
       " ('romes', 0.2022033929824829),\n",
       " ('byzantine', 0.2013220489025116),\n",
       " ('assassinated', 0.18931180238723755),\n",
       " ('tokyo', 0.18898290395736694),\n",
       " ('construction', 0.18593069911003113),\n",
       " ('conquest', 0.18502110242843628),\n",
       " ('milan', 0.18497797846794128)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['president', 'germany'], negative='usa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('exile', 0.20584151148796082),\n",
       " ('conquest', 0.19162502884864807),\n",
       " ('assassinated', 0.18330737948417664),\n",
       " ('pope', 0.16349422931671143),\n",
       " ('jerusalem', 0.16297361254692078),\n",
       " ('deposed', 0.16267861425876617),\n",
       " ('emperors', 0.16242769360542297),\n",
       " ('minister', 0.15971383452415466),\n",
       " ('mecca', 0.15835599601268768),\n",
       " ('romes', 0.15732252597808838)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['president', 'france'], negative='usa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'doesnt_match()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/learn-env/lib/python3.6/site-packages/gensim/models/keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'frog'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(['breakfast', 'lunch', 'frog', 'food'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/learn-env/lib/python3.6/site-packages/gensim/models/keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'this'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(['lunch', 'this'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/learn-env/lib/python3.6/site-packages/gensim/models/keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bush'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(['tree', 'flower', 'bush', 'plant', 'toothbrush'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/learn-env/lib/python3.6/site-packages/gensim/models/keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'toothbrush'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(['tree', 'flower', 'plant', 'toothbrush'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'closer_than()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prince',\n",
       " 'emperor',\n",
       " 'kings',\n",
       " 'pope',\n",
       " 'iv',\n",
       " 'vi',\n",
       " 'viii',\n",
       " 'crowned',\n",
       " 'frederick',\n",
       " 'vii',\n",
       " 'gustav',\n",
       " 'stuart',\n",
       " 'dane',\n",
       " 'tudor',\n",
       " 'isabella',\n",
       " 'quest',\n",
       " 'coronation',\n",
       " 'reigning',\n",
       " 'adrian',\n",
       " 'cyrus',\n",
       " 'viiis',\n",
       " 'xiii',\n",
       " 'iis',\n",
       " 'czars',\n",
       " 'alfonso',\n",
       " '1547',\n",
       " 'handel',\n",
       " '1742',\n",
       " 'umberto',\n",
       " '1760',\n",
       " 'prophecy',\n",
       " 'olaf',\n",
       " 'hittite',\n",
       " 'centurys',\n",
       " '1540',\n",
       " '1653',\n",
       " 'trickster',\n",
       " 'lionhearted',\n",
       " 'courtier',\n",
       " 'inquisitor',\n",
       " 'pepin',\n",
       " '1589',\n",
       " 'moliere',\n",
       " 'saxon',\n",
       " 'deacon',\n",
       " '1631',\n",
       " 'ides',\n",
       " 'supremacy',\n",
       " '1632',\n",
       " 'wilhelmina',\n",
       " 'anointed',\n",
       " 'rightful',\n",
       " 'martel',\n",
       " 'singh',\n",
       " 'martyrdom',\n",
       " '1509',\n",
       " '1599',\n",
       " 'henrik',\n",
       " 'henrietta',\n",
       " 'sforza',\n",
       " 'affirmed',\n",
       " '331',\n",
       " 'olav',\n",
       " 'plutarch',\n",
       " 'canute',\n",
       " 'evacuated',\n",
       " '1647',\n",
       " 'cranmer',\n",
       " '751',\n",
       " 'sihanouk',\n",
       " 'theban',\n",
       " 'cato',\n",
       " 'wisest',\n",
       " '1523',\n",
       " 'heretic',\n",
       " 'agrippa',\n",
       " 'camillas',\n",
       " 'stirling']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which words are closer to 'king' than 'queen' is?\n",
    "\n",
    "model.wv.closer_than('king', 'queen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'distance()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this it will make more sense to\n",
    "# normalize our vectors.\n",
    "\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.distance('king', 'king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6370022892951965"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.distance('joy', 'happiness')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'evaluate_word_analogies()'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `evaluate_word_analogies()` method takes in a string of quadruples, properly formatted (see [here](https://radimrehurek.com/gensim/models/keyedvectors.html)), and returns a list of dictionaries. Each dictionary has two keys: 'correct' and 'incorrect', the values for which are lists of the analogies that the model correctly or incorrectly predicted.\n",
    "\n",
    "Check out [this text file](https://raw.githubusercontent.com/nicholas-leonard/word2vec/master/questions-words.txt)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.0'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "relatives = model.wv.evaluate_word_analogies(\"\"\"https://raw.githubusercontent.com/nicholas-leonard/word2vec/master/questions-words.txt\"\"\")[1][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relatives['correct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relatives['incorrect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BOY', 'GIRL', 'FATHER', 'MOTHER'),\n",
       " ('BOY', 'GIRL', 'HIS', 'HER'),\n",
       " ('BOY', 'GIRL', 'KING', 'QUEEN'),\n",
       " ('BOY', 'GIRL', 'SON', 'DAUGHTER'),\n",
       " ('BOY', 'GIRL', 'UNCLE', 'AUNT')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relatives['correct'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BOY', 'GIRL', 'BROTHER', 'SISTER'),\n",
       " ('BOY', 'GIRL', 'BROTHERS', 'SISTERS'),\n",
       " ('BOY', 'GIRL', 'DAD', 'MOM'),\n",
       " ('BOY', 'GIRL', 'GRANDFATHER', 'GRANDMOTHER'),\n",
       " ('BOY', 'GIRL', 'GRANDPA', 'GRANDMA')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relatives['incorrect'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
